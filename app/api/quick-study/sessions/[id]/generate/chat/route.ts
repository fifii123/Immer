export const runtime = 'nodejs'
import { NextRequest } from 'next/server'
import { OpenAI } from 'openai'

// Initialize OpenAI client
const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY
})

// Types
interface Source {
  id: string;
  name: string;
  type: 'pdf' | 'youtube' | 'text' | 'docx' | 'image' | 'audio' | 'url';
  status: 'ready' | 'processing' | 'error';
  size?: string;
  duration?: string;
  pages?: number;
  extractedText?: string;
  wordCount?: number;
  processingError?: string;
  subtype?: string;
}

interface SessionData {
  sources: Source[]
  outputs: any[]
  createdAt: Date
}

// Global in-memory store
declare global {
  var quickStudySessions: Map<string, SessionData> | undefined
}

const sessions = globalThis.quickStudySessions ?? new Map<string, SessionData>()
globalThis.quickStudySessions = sessions

export async function POST(
  request: NextRequest,
  { params }: { params: { id: string } }
) {
  try {
    const sessionId = params.id
    
    console.log(`ğŸ’¬ Chat request for session: ${sessionId}`)
    
    // Parse request body
    const body = await request.json()
    const { sourceId, message, conversationHistory } = body
    
    if (!sourceId || !message) {
      return Response.json(
        { message: 'Missing sourceId or message' },
        { status: 400 }
      )
    }
    
    // Check if session exists
    const sessionData = sessions.get(sessionId)
    if (!sessionData) {
      console.log(`âŒ Session not found: ${sessionId}`)
      return Response.json(
        { message: 'Session not found' },
        { status: 404 }
      )
    }
    
    // Find source
    const source = sessionData.sources.find(s => s.id === sourceId)
    if (!source) {
      console.log(`âŒ Source not found: ${sourceId}`)
      return Response.json(
        { message: 'Source not found' },
        { status: 404 }
      )
    }
    
    if (source.status !== 'ready') {
      return Response.json(
        { message: 'Source is not ready for processing' },
        { status: 400 }
      )
    }
    
    console.log(`ğŸ¤– Processing chat message for source: ${source.name}`)
    
    // Create streaming response
    const stream = new ReadableStream({
      async start(controller) {
        try {
          await streamChatResponse(
            source,
            message,
            conversationHistory || [],
            controller
          )
        } catch (error) {
          console.error('âŒ Error in chat stream:', error)
          controller.error(error)
        }
      }
    })
    
    return new Response(stream, {
      headers: {
        'Content-Type': 'text/stream',
        'Cache-Control': 'no-cache',
        'Connection': 'keep-alive',
      },
    })
    
  } catch (error) {
    console.error('âŒ Error in chat endpoint:', error)
    
    return Response.json(
      { message: 'Chat request failed' },
      { status: 500 }
    )
  }
}

// Stream chat response using OpenAI
async function streamChatResponse(
  source: Source, 
  userMessage: string, 
  conversationHistory: any[],
  controller: ReadableStreamDefaultController
) {
  console.log(`ğŸ¤– Generating streaming chat response for: ${source.name}`)
  
  try {
    // Prepare conversation context
    const systemPrompt = createSystemPrompt(source)
    const messages = [
      { role: 'system', content: systemPrompt },
      ...conversationHistory.map(msg => ({
        role: msg.role,
        content: msg.content
      })),
      { role: 'user', content: userMessage }
    ]
    
    // Create streaming completion
    const completion = await openai.chat.completions.create({
      model: "gpt-4-1106-preview",
      messages: messages as any,
      temperature: 0.7,
      max_tokens: 1500,
      stream: true
    })
    
    let fullResponse = ''
    
    // Stream the response
    for await (const chunk of completion) {
      const content = chunk.choices[0]?.delta?.content || ''
      
      if (content) {
        fullResponse += content
        
        // Send chunk to client
        const data = JSON.stringify({ 
          type: 'chunk', 
          content: content 
        })
        controller.enqueue(new TextEncoder().encode(`data: ${data}\n\n`))
      }
    }
    
    // Send completion signal
    const completeData = JSON.stringify({ 
      type: 'complete', 
      fullContent: fullResponse 
    })
    controller.enqueue(new TextEncoder().encode(`data: ${completeData}\n\n`))
    
    console.log(`âœ… Chat response streamed successfully`)
    controller.close()
    
  } catch (error) {
    console.error('Error streaming chat response:', error)
    
    // Send error to client
    const errorData = JSON.stringify({ 
      type: 'error', 
      message: 'Failed to generate response' 
    })
    controller.enqueue(new TextEncoder().encode(`data: ${errorData}\n\n`))
    controller.close()
    
    throw error
  }
}

// Create system prompt based on source
function createSystemPrompt(source: Source): string {
  const basePrompt = `JesteÅ› inteligentnym asystentem AI specjalizujÄ…cym siÄ™ w pomocy przy nauce. Odpowiadasz na pytania uÅ¼ytkownika na podstawie dostarczonego materiaÅ‚u ÅºrÃ³dÅ‚owego.

WAÅ»NE ZASADY:
1. Odpowiadaj TYLKO na podstawie dostarczonego materiaÅ‚u ÅºrÃ³dÅ‚owego
2. JeÅ›li pytanie wykracza poza materiaÅ‚, uprzejmie poinformuj o tym
3. UÅ¼ywaj jasnego, zrozumiaÅ‚ego jÄ™zyka
4. Dawaj konkretne przykÅ‚ady z materiaÅ‚u gdy to moÅ¼liwe
5. JeÅ›li nie jesteÅ› pewien, powiedz to wprost
6. Formatuj odpowiedzi w sposÃ³b czytelny (uÅ¼ywaj akapitÃ³w, list gdy potrzeba)

MATERIAÅ Å¹RÃ“DÅOWY: "${source.name}" (${source.type})`
  
  // Add source content if available
  if (source.extractedText && source.type !== 'image' && source.type !== 'audio') {
    const contentPreview = source.extractedText.slice(0, 8000) // Limit to prevent token overflow
    return `${basePrompt}

TREÅšÄ† MATERIAÅU:
${contentPreview}

${source.extractedText.length > 8000 ? '\n[MateriaÅ‚ zostaÅ‚ skrÃ³cony - bazuj na dostÄ™pnej czÄ™Å›ci]' : ''}`
  }
  
  // For unsupported source types
  const unsupportedMessage = getUnsupportedSourceMessage(source.type)
  return `${basePrompt}

${unsupportedMessage}

Odpowiadaj na pytania ogÃ³lne dotyczÄ…ce tego typu materiaÅ‚u i pomagaj uÅ¼ytkownikowi zrozumieÄ‡, jak bÄ™dzie moÅ¼na go przetworzyÄ‡ gdy funkcja zostanie zaimplementowana.`
}

// Get message for unsupported source types
function getUnsupportedSourceMessage(sourceType: string): string {
  switch (sourceType) {
    case 'docx':
      return 'UWAGA: Przetwarzanie plikÃ³w DOCX nie jest jeszcze zaimplementowane. MogÄ™ udzieliÄ‡ ogÃ³lnych informacji o pracy z dokumentami Word.'
    case 'image':
      return 'UWAGA: Analiza obrazÃ³w (OCR) nie jest jeszcze zaimplementowana. MogÄ™ udzieliÄ‡ ogÃ³lnych informacji o pracy z materiaÅ‚ami wizualnymi.'
    case 'audio':
      return 'UWAGA: Transkrypcja audio nie jest jeszcze zaimplementowana. MogÄ™ udzieliÄ‡ ogÃ³lnych informacji o pracy z materiaÅ‚ami audio.'
    case 'youtube':
      return 'UWAGA: Analiza transkrypcji YouTube nie jest jeszcze zaimplementowana. MogÄ™ udzieliÄ‡ ogÃ³lnych informacji o uczeniu siÄ™ z filmÃ³w.'
    case 'url':
      return 'UWAGA: Ekstrakcja treÅ›ci z stron internetowych nie jest jeszcze zaimplementowana. MogÄ™ udzieliÄ‡ ogÃ³lnych informacji o pracy z treÅ›ciami web.'
    default:
      return 'MateriaÅ‚ nie zawiera jeszcze przetworzonej treÅ›ci.'
  }
}